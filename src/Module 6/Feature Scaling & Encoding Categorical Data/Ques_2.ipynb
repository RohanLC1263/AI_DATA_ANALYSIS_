{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5: Label Encoding vs One-Hot Encoding\n",
    "# Task: Show the difference between Label Encoding and One-Hot Encoding on the Titanic dataset for the 'Sex' feature.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 6: Combining Feature Scaling Techniques\n",
    "# Task: Demonstrate combining Min-Max Scaling and Standardization for the same datasetand explain the results.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 7: Handling Multiple Categorical Features\n",
    "# Task: Handle multiple categorical features ('Sex', 'Embarked') from the Titanic dataset using One-Hot Encoding.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 8: Ordinal Encoding for Ranked Categories\n",
    "# Task: Ordinal encode 'Pclass' (Passenger class) from the Titanic dataset considering passenger class as a ranked feature.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 9: Impact of Scaling on Different Algorithms\n",
    "# Task: Investigate the impact of different scaling techniques on a decision tree model and compare it with a SVM.\n",
    "\n",
    "\n",
    "\n",
    "# Question 10: Custom Transformations for Categorical Features\n",
    "# Task: Implement a custom transformation function for encoding high cardinality categorical features efficiently.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data sample:\n",
      "      sex  pclass embarked\n",
      "0    male       3        S\n",
      "1  female       1        C\n",
      "2  female       3        S\n",
      "3  female       1        S\n",
      "4    male       3        S\n",
      "\n",
      "--- Question 5: Label Encoding vs One-Hot Encoding ---\n",
      "      sex  sex_label  sex_onehot_female  sex_onehot_male\n",
      "0    male          1                0.0              1.0\n",
      "1  female          0                1.0              0.0\n",
      "2  female          0                1.0              0.0\n",
      "3  female          0                1.0              0.0\n",
      "4    male          1                0.0              1.0\n",
      "\n",
      "--- Question 6: Combining Min-Max Scaling and Standardization ---\n",
      "First 5 rows after Min-Max scaling and Standardization:\n",
      "[[-0.58961986 -0.50023975]\n",
      " [ 0.64484799  0.78894661]\n",
      " [-0.28100289 -0.48664993]\n",
      " [ 0.41338527  0.42286111]\n",
      " [ 0.41338527 -0.4841333 ]]\n",
      "\n",
      "--- Question 7: One-Hot Encoding 'sex' and 'embarked' ---\n",
      "      sex embarked  sex_male  embarked_Q  embarked_S\n",
      "0    male        S       1.0         0.0         1.0\n",
      "1  female        C       0.0         0.0         0.0\n",
      "2  female        S       0.0         0.0         1.0\n",
      "3  female        S       0.0         0.0         1.0\n",
      "4    male        S       1.0         0.0         1.0\n",
      "\n",
      "--- Question 8: Ordinal Encoding for 'pclass' ---\n",
      "   pclass  pclass_encoded\n",
      "0       3             2.0\n",
      "1       1             0.0\n",
      "2       3             2.0\n",
      "3       1             0.0\n",
      "4       3             2.0\n",
      "\n",
      "--- Question 9: Impact of Scaling on Decision Tree vs SVM ---\n",
      "Decision Tree accuracy (no scaling): 0.776\n",
      "SVM accuracy (with standard scaling): 0.825\n",
      "\n",
      "--- Question 10: Custom encoding for high cardinality categorical features ---\n",
      "  embarked embarked_custom_encoded\n",
      "0        S                       S\n",
      "1        C                       C\n",
      "2        S                       S\n",
      "3        S                       S\n",
      "4        S                       S\n",
      "  embarked_custom_encoded  embarked_custom_encoded_C  \\\n",
      "0                       S                        0.0   \n",
      "1                       C                        1.0   \n",
      "2                       S                        0.0   \n",
      "3                       S                        0.0   \n",
      "4                       S                        0.0   \n",
      "\n",
      "   embarked_custom_encoded_Other  embarked_custom_encoded_S  \n",
      "0                            0.0                        1.0  \n",
      "1                            0.0                        0.0  \n",
      "2                            0.0                        1.0  \n",
      "3                            0.0                        1.0  \n",
      "4                            0.0                        1.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder, MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load Titanic dataset (using seaborn for convenience)\n",
    "import seaborn as sns\n",
    "df = sns.load_dataset('titanic').dropna(subset=['sex', 'pclass', 'embarked'])  # Drop rows with missing key categorical data for simplicity\n",
    "\n",
    "print(\"Original data sample:\")\n",
    "print(df[['sex', 'pclass', 'embarked']].head())\n",
    "\n",
    "# --- Question 5: Label Encoding vs One-Hot Encoding on 'sex' ---\n",
    "print(\"\\n--- Question 5: Label Encoding vs One-Hot Encoding ---\")\n",
    "label_enc = LabelEncoder()\n",
    "df['sex_label'] = label_enc.fit_transform(df['sex'])\n",
    "\n",
    "# OneHotEncoder fix: use drop=None to get both columns\n",
    "onehot_enc = OneHotEncoder(sparse_output=False, drop=None)\n",
    "sex_onehot = onehot_enc.fit_transform(df[['sex']])\n",
    "df['sex_onehot_female'] = sex_onehot[:,0]\n",
    "df['sex_onehot_male'] = sex_onehot[:,1]\n",
    "\n",
    "print(df[['sex', 'sex_label', 'sex_onehot_female', 'sex_onehot_male']].head())\n",
    "\n",
    "# --- Question 6: Combining Min-Max Scaling and Standardization ---\n",
    "print(\"\\n--- Question 6: Combining Min-Max Scaling and Standardization ---\")\n",
    "num_features = ['age', 'fare']\n",
    "# Fill missing numerical data for scaling demonstration\n",
    "df[num_features] = df[num_features].fillna(df[num_features].mean())\n",
    "\n",
    "scaler_minmax = MinMaxScaler()\n",
    "df_minmax = scaler_minmax.fit_transform(df[num_features])\n",
    "\n",
    "scaler_standard = StandardScaler()\n",
    "df_standard = scaler_standard.fit_transform(df_minmax)  # Standardize the min-max scaled data\n",
    "\n",
    "print(\"First 5 rows after Min-Max scaling and Standardization:\")\n",
    "print(df_standard[:5])\n",
    "\n",
    "# --- Question 7: Handling multiple categorical features with One-Hot Encoding ---\n",
    "print(\"\\n--- Question 7: One-Hot Encoding 'sex' and 'embarked' ---\")\n",
    "cat_features = ['sex', 'embarked']\n",
    "onehot_enc_multi = OneHotEncoder(sparse_output=False, drop='first')\n",
    "encoded_features = onehot_enc_multi.fit_transform(df[cat_features])\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=onehot_enc_multi.get_feature_names_out(cat_features))\n",
    "df = pd.concat([df.reset_index(drop=True), encoded_df], axis=1)\n",
    "print(df[cat_features + list(encoded_df.columns)].head())\n",
    "\n",
    "# --- Question 8: Ordinal Encoding for 'pclass' (ranked categories) ---\n",
    "print(\"\\n--- Question 8: Ordinal Encoding for 'pclass' ---\")\n",
    "# Correct order from high class(1) to low class(3)\n",
    "ordinal_encoder = OrdinalEncoder(categories=[[1, 2, 3]])\n",
    "df['pclass_encoded'] = ordinal_encoder.fit_transform(df[['pclass']])\n",
    "print(df[['pclass', 'pclass_encoded']].head())\n",
    "\n",
    "# --- Question 9: Impact of Scaling on Decision Tree vs SVM ---\n",
    "print(\"\\n--- Question 9: Impact of Scaling on Decision Tree vs SVM ---\")\n",
    "# Prepare features and target\n",
    "features = ['age', 'fare', 'pclass_encoded'] + list(encoded_df.columns)\n",
    "X = df[features].fillna(0)\n",
    "y = df['survived']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Decision Tree (no scaling needed)\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "acc_dt = accuracy_score(y_test, y_pred_dt)\n",
    "\n",
    "# SVM with StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "svm = SVC(random_state=42)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "y_pred_svm = svm.predict(X_test_scaled)\n",
    "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "print(f\"Decision Tree accuracy (no scaling): {acc_dt:.3f}\")\n",
    "print(f\"SVM accuracy (with standard scaling): {acc_svm:.3f}\")\n",
    "\n",
    "# --- Question 10: Custom transformation for high cardinality categorical features ---\n",
    "print(\"\\n--- Question 10: Custom encoding for high cardinality categorical features ---\")\n",
    "\n",
    "def custom_high_cardinality_encoder(series, top_n=5):\n",
    "    \"\"\"Encode top_n frequent categories and group others into 'Other'.\"\"\"\n",
    "    top_categories = series.value_counts().nlargest(top_n).index\n",
    "    return series.apply(lambda x: x if x in top_categories else 'Other')\n",
    "\n",
    "# Example with 'embarked' (not high cardinality but for demo)\n",
    "df['embarked_custom_encoded'] = custom_high_cardinality_encoder(df['embarked'], top_n=2)\n",
    "print(df[['embarked', 'embarked_custom_encoded']].head())\n",
    "\n",
    "# One-hot encode the custom encoded feature\n",
    "onehot_enc_custom = OneHotEncoder(sparse_output=False, drop=None)\n",
    "custom_encoded = onehot_enc_custom.fit_transform(df[['embarked_custom_encoded']])\n",
    "custom_encoded_df = pd.DataFrame(custom_encoded, columns=onehot_enc_custom.get_feature_names_out(['embarked_custom_encoded']))\n",
    "df = pd.concat([df.reset_index(drop=True), custom_encoded_df], axis=1)\n",
    "\n",
    "print(df[['embarked_custom_encoded'] + list(custom_encoded_df.columns)].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
