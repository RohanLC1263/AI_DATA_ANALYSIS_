{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automating Data Cleaning in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "    Task: Basic Pipeline with Scaling\n",
    "1. Objective: Create a pipeline that scales numerical features in a dataset.\n",
    "2. Steps:\n",
    "    - Load a sample dataset with Pandas.\n",
    "    - Define a pipeline using Pipeline from sklearn.pipeline .\n",
    "    - Use StandardScaler to scale features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Original Dataset:\n",
      "\n",
      "   Age  Salary\n",
      "0   55   76530\n",
      "1   40   68044\n",
      "2   24   47274\n",
      "3   28   65673\n",
      "4   30   35004\n",
      "5   52   39549\n",
      "6   54   51291\n",
      "7   26   71665\n",
      "8   37   85212\n",
      "9   22   59668\n",
      "\n",
      "ðŸ“Š Scaled Dataset using Pipeline:\n",
      "\n",
      "        Age    Salary\n",
      "0  1.490202  1.062553\n",
      "1  0.262014  0.517367\n",
      "2 -1.048054 -0.817008\n",
      "3 -0.720537  0.365042\n",
      "4 -0.556779 -1.605298\n",
      "5  1.244564 -1.313303\n",
      "6  1.408323 -0.558934\n",
      "7 -0.884296  0.750000\n",
      "8  0.016376  1.620331\n",
      "9 -1.211813 -0.020751\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Load a sample dataset\n",
    "data = {\n",
    "    'Age': np.random.randint(20, 60, size=10),\n",
    "    'Salary': np.random.randint(30000, 100000, size=10)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"ðŸ“¦ Original Dataset:\\n\")\n",
    "print(df)\n",
    "\n",
    "# Step 2: Define a pipeline\n",
    "scaling_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Step 3: Apply pipeline to scale features\n",
    "scaled_data = scaling_pipeline.fit_transform(df)\n",
    "\n",
    "# Convert scaled data back to a DataFrame for readability\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "print(\"\\nðŸ“Š Scaled Dataset using Pipeline:\\n\")\n",
    "print(scaled_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Task: Pipeline with Imputation\n",
    "1. Objective: Automate data cleaning by handling missing values.\n",
    "2. Steps:\n",
    "    - Load a dataset with missing values.\n",
    "    - Define a pipeline to use SimpleImputer for filling missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Original Dataset with Missing Values:\n",
      "\n",
      "    Age   Salary\n",
      "0  25.0  50000.0\n",
      "1  30.0      NaN\n",
      "2   NaN  60000.0\n",
      "3  45.0  80000.0\n",
      "4  35.0      NaN\n",
      "\n",
      "ðŸ§¼ Cleaned Dataset after Imputation:\n",
      "\n",
      "     Age        Salary\n",
      "0  25.00  50000.000000\n",
      "1  30.00  63333.333333\n",
      "2  33.75  60000.000000\n",
      "3  45.00  80000.000000\n",
      "4  35.00  63333.333333\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Create a sample dataset with missing values\n",
    "data = {\n",
    "    'Age': [25, 30, np.nan, 45, 35],\n",
    "    'Salary': [50000, np.nan, 60000, 80000, np.nan]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"ðŸ“¦ Original Dataset with Missing Values:\\n\")\n",
    "print(df)\n",
    "\n",
    "# Step 2: Define a pipeline with imputation\n",
    "imputation_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean'))  # Replace missing values with mean\n",
    "])\n",
    "\n",
    "# Step 3: Apply the pipeline to the data\n",
    "imputed_data = imputation_pipeline.fit_transform(df)\n",
    "\n",
    "# Convert imputed data back to DataFrame\n",
    "imputed_df = pd.DataFrame(imputed_data, columns=df.columns)\n",
    "print(\"\\nðŸ§¼ Cleaned Dataset after Imputation:\\n\")\n",
    "print(imputed_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
