{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Understanding and Defining Data Quality Metrics\n",
    "**Description**: Learn how to define basic data quality metrics such as completeness, validity, and uniqueness for a simple dataset.\n",
    "\n",
    "**Steps**:\n",
    "1. Dataset: Use a CSV with columns like Name , Email , Age .\n",
    "2. Metric Definitions:\n",
    "    - Completeness: Percentage of non-null values.\n",
    "    - Validity: % of email fields containing @ .\n",
    "    - Uniqueness: Count distinct entries in the Email column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Calculating Data Quality Score\n",
    "**Description**: Aggregate multiple metrics to calculate an overall data quality score.\n",
    "\n",
    "**Steps**:\n",
    "1. Formula: Simple average of all metrics defined in Task 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Creating Expectations for a CSV\n",
    "**Description**: Develop basic data quality expectations using Great Expectations.\n",
    "\n",
    "**Steps**:\n",
    "1. Expectation Suite\n",
    "2. Define Expectations for Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Running and Validating Expectations\n",
    "**Description**: Run the created expectations and generate an output report.\n",
    "\n",
    "**Steps**:\n",
    "1. Validate\n",
    "2. Generate HTML Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Automating Data Quality Score Calculation\n",
    "**Description**: Automate the data quality score via a script that integrates with Great\n",
    "Expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pytest\n",
      "  Downloading pytest-8.3.5-py3-none-any.whl (343 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.6/343.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tomli>=1\n",
      "  Downloading tomli-2.2.1-py3-none-any.whl (14 kB)\n",
      "Collecting pluggy<2,>=1.5\n",
      "  Downloading pluggy-1.6.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: packaging in /home/vscode/.local/lib/python3.10/site-packages (from pytest) (25.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /home/vscode/.local/lib/python3.10/site-packages (from pytest) (1.3.0)\n",
      "Collecting iniconfig\n",
      "  Downloading iniconfig-2.1.0-py3-none-any.whl (6.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/vscode/.local/lib/python3.10/site-packages (from exceptiongroup>=1.0.0rc8->pytest) (4.13.2)\n",
      "Installing collected packages: tomli, pluggy, iniconfig, pytest\n",
      "Successfully installed iniconfig-2.1.0 pluggy-1.6.0 pytest-8.3.5 tomli-2.2.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "\n",
    "! pip install pytest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Leveraging Data Quality Metrics for Automated Data Cleaning\n",
    "**Description**: Implement a system where if data quality metrics fall below a threshold,\n",
    "automated data cleaning scripts are triggered.\n",
    "\n",
    "**Steps**:\n",
    "1. Define Cleaning Logic\n",
    "2. Integrate with Great Expectations:\n",
    "    - Use an action within the Great Expectations action list that only triggers if quality score is below a threshold, automating the cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'your_module'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytest\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myour_module\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m completeness, validity_email, uniqueness_email, clean_data  \u001b[38;5;66;03m# Replace 'your_module' with your script name without .py\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;129m@pytest\u001b[39m\u001b[38;5;241m.\u001b[39mfixture\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msample_df\u001b[39m():\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlice\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBob\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmail\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malice@example.com\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid_email\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m25\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m30\u001b[39m]\n\u001b[1;32m     12\u001b[0m     })\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'your_module'"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pytest\n",
    "import pandas as pd\n",
    "from your_module import completeness, validity_email, uniqueness_email, clean_data  # Replace 'your_module' with your script name without .py\n",
    "\n",
    "@pytest.fixture\n",
    "def sample_df():\n",
    "    return pd.DataFrame({\n",
    "        \"Name\": [\"Alice\", None, \"Bob\"],\n",
    "        \"Email\": [\"alice@example.com\", \"invalid_email\", None],\n",
    "        \"Age\": [25, None, 30]\n",
    "    })\n",
    "\n",
    "def test_completeness(sample_df):\n",
    "    comp = completeness(sample_df)\n",
    "    assert comp[\"Name\"] == pytest.approx(2/3 * 100)\n",
    "    assert comp[\"Email\"] == pytest.approx(2/3 * 100)\n",
    "    assert comp[\"Age\"] == pytest.approx(2/3 * 100)\n",
    "\n",
    "def test_validity_email(sample_df):\n",
    "    val = validity_email(sample_df)\n",
    "    # Only one valid email 'alice@example.com' out of 2 non-null emails\n",
    "    assert val == pytest.approx(0.5 * 100)\n",
    "\n",
    "def test_uniqueness_email(sample_df):\n",
    "    uniq = uniqueness_email(sample_df)\n",
    "    # Two non-null emails, both unique\n",
    "    assert uniq == 100\n",
    "\n",
    "def test_clean_data(sample_df):\n",
    "    cleaned = clean_data(sample_df)\n",
    "    # After cleaning, invalid email row removed, missing name filled\n",
    "    assert cleaned[\"Name\"].isnull().sum() == 0\n",
    "    assert all(cleaned[\"Email\"].apply(lambda x: \"@\" in x))\n",
    "    assert cleaned.shape[0] == 1  # Only one valid email row remains\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
