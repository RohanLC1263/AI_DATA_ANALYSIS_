{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance of Data Cleaning\n",
    "\n",
    "# 1. Missing Values: Missing data points in a dataset can lead to biased results.\n",
    "#     Task 1: Load a dataset and identify which columns have missing values.\n",
    "#     Task 2: Replace missing values in a dataset with the column mean or mode.\n",
    "#     Task 3: Compare model performance with and without handling missing values.\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Duplicate Data: Repeated data points can skew analysis and model results.\n",
    "#     Task 1: Identify and remove duplicate entries from a dataset using a programming language or tool.\n",
    "#     Task 2: Document the before-and-after dataset shape to understand the impact of duplicates.\n",
    "#     Task 3: Explain to a classmate how duplicate data can affect prediction accuracy.\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Incorrect Data Types: Data stored in incorrect formats can lead to parsing errors or incorrect analysis.\n",
    "#     Task 1: Convert a column of string numbers to integers in a dataset.\n",
    "#     Task 2: Identify and correct columns with inconsistent data types in a dataset.\n",
    "#     Task 3: Discuss why correct data types are critical for feature engineering.\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Outliers & Inconsistencies: Irregularities in data can mislead statistical analysis and model predictions.\n",
    "#     Task 1: Visualize a dataset and identify outliers using a boxplot.\n",
    "#     Task 2: Remove or adjust outliers and re-analyze the dataset.\n",
    "#     Task 3: Research and report on a technique for handling outliers effectively.\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset Shape: (11, 4)\n",
      "\n",
      "--- Task 1: Identify Missing Values ---\n",
      "Age           1\n",
      "Income        1\n",
      "Experience    1\n",
      "dtype: int64\n",
      "\n",
      "--- Task 2: Fill Missing Values ---\n",
      "Filled missing values in Age with mean: 127.3\n",
      "Filled missing values in Income with mean: 150100.0\n",
      "Filled missing values in Experience with mean: 5.3\n",
      "\n",
      "--- Task 3: Compare model performance with/without missing value handling ---\n",
      "Without Handling Missing Values (drop NA) - MSE: 19898776.38\n",
      "With Missing Values Filled (mean imputation) - MSE: 830302623.08\n",
      "\n",
      "--- Task 1: Identify & Remove Duplicates ---\n",
      "Initial dataset shape: (11, 4)\n",
      "Number of duplicate rows: 2\n",
      "Dataset shape after removing duplicates: (9, 4)\n",
      "\n",
      "--- Task 3: Impact of duplicates on prediction accuracy ---\n",
      "Duplicates can lead to overfitting and biased model results because repeated data points skew the distribution.\n",
      "\n",
      "--- Task 1 & 2: Fixing Incorrect Data Types ---\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (10) does not match length of index (9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 69\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Task 1 & 2: Fixing Incorrect Data Types ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Add an example column with incorrect types\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYears_at_Company\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m6\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m10\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBefore conversion:\u001b[39m\u001b[38;5;124m\"\u001b[39m, df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYears_at_Company\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     72\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYears_at_Company\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYears_at_Company\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:4091\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4088\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4089\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4090\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 4091\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:4300\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4291\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4292\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4293\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4298\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4299\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4300\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4303\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4304\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4305\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m   4306\u001b[0m     ):\n\u001b[1;32m   4307\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4308\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:5039\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5036\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   5038\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 5039\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/common.py:561\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    564\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    565\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (10) does not match length of index (9)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Sample dataset with issues\n",
    "data = {\n",
    "    'Age': [25, 27, np.nan, 45, 33, 27, 27, 1000, 29, 33, 27],\n",
    "    'Income': [50000, 54000, 58000, 62000, np.nan, 54000, 54000, 1000000, 56000, 59000, 54000],\n",
    "    'Gender': ['M', 'F', 'F', 'M', 'F', 'F', 'F', 'M', 'F', 'F', 'F'],\n",
    "    'Experience': [1, 3, 5, 7, 9, np.nan, 3, 12, 6, 4, 3]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original Dataset Shape:\", df.shape)\n",
    "\n",
    "# ----------- 1. Missing Values --------------\n",
    "print(\"\\n--- Task 1: Identify Missing Values ---\")\n",
    "missing_counts = df.isnull().sum()\n",
    "print(missing_counts[missing_counts > 0])\n",
    "\n",
    "print(\"\\n--- Task 2: Fill Missing Values ---\")\n",
    "# Fill numerical columns with mean\n",
    "for col in ['Age', 'Income', 'Experience']:\n",
    "    if df[col].isnull().any():\n",
    "        mean_val = df[col].mean()\n",
    "        df[col].fillna(mean_val, inplace=True)\n",
    "        print(f\"Filled missing values in {col} with mean: {mean_val}\")\n",
    "\n",
    "# --------- Model comparison ---------\n",
    "print(\"\\n--- Task 3: Compare model performance with/without missing value handling ---\")\n",
    "\n",
    "# For demonstration, simulate original dataset with missing values for comparison\n",
    "df_missing = pd.DataFrame(data)\n",
    "\n",
    "# Prepare data for modeling (simple linear regression predicting Income from Age & Experience)\n",
    "def prepare_and_evaluate(dataframe, desc):\n",
    "    X = dataframe[['Age', 'Experience']]\n",
    "    y = dataframe['Income']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    print(f\"{desc} - MSE: {mse:.2f}\")\n",
    "\n",
    "prepare_and_evaluate(df_missing.dropna(), \"Without Handling Missing Values (drop NA)\")\n",
    "prepare_and_evaluate(df, \"With Missing Values Filled (mean imputation)\")\n",
    "\n",
    "# ----------- 2. Duplicate Data --------------\n",
    "print(\"\\n--- Task 1: Identify & Remove Duplicates ---\")\n",
    "print(\"Initial dataset shape:\", df.shape)\n",
    "duplicates = df.duplicated()\n",
    "print(f\"Number of duplicate rows: {duplicates.sum()}\")\n",
    "df = df.drop_duplicates()\n",
    "print(\"Dataset shape after removing duplicates:\", df.shape)\n",
    "\n",
    "print(\"\\n--- Task 3: Impact of duplicates on prediction accuracy ---\")\n",
    "print(\"Duplicates can lead to overfitting and biased model results because repeated data points skew the distribution.\")\n",
    "\n",
    "# ----------- 3. Incorrect Data Types --------------\n",
    "print(\"\\n--- Task 1 & 2: Fixing Incorrect Data Types ---\")\n",
    "\n",
    "# Add an example column with incorrect types\n",
    "df['Years_at_Company'] = ['5', '3', '4', '6', '2', '4', '3', '10', '4', '3']\n",
    "\n",
    "print(\"Before conversion:\", df['Years_at_Company'].dtype)\n",
    "df['Years_at_Company'] = pd.to_numeric(df['Years_at_Company'], errors='coerce')\n",
    "print(\"After conversion:\", df['Years_at_Company'].dtype)\n",
    "\n",
    "print(\"\\n--- Task 3: Importance of Correct Data Types ---\")\n",
    "print(\"Correct data types enable proper mathematical operations, memory efficiency, and compatibility with ML algorithms.\")\n",
    "\n",
    "# ----------- 4. Outliers & Inconsistencies --------------\n",
    "print(\"\\n--- Task 1: Visualize Outliers using Boxplot ---\")\n",
    "sns.boxplot(x=df['Age'])\n",
    "plt.title('Boxplot of Age')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- Task 2: Remove Outliers ---\")\n",
    "# Define outlier threshold (e.g., Age > 100 as outlier)\n",
    "outlier_threshold = 100\n",
    "df_no_outliers = df[df['Age'] < outlier_threshold]\n",
    "print(f\"Removed {df.shape[0] - df_no_outliers.shape[0]} outliers from Age.\")\n",
    "\n",
    "print(\"\\n--- Task 3: Report on Outlier Handling Technique ---\")\n",
    "print(\"\"\"A common technique to handle outliers is the IQR method:\n",
    "- Calculate Q1 (25th percentile) and Q3 (75th percentile).\n",
    "- Compute IQR = Q3 - Q1.\n",
    "- Define outliers as points outside [Q1 - 1.5*IQR, Q3 + 1.5*IQR].\n",
    "This method helps identify extreme values while retaining legitimate data.\"\"\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
